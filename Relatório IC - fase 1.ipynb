{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5bcc64c",
   "metadata": {},
   "source": [
    "## 1 - Introdução\n",
    "\n",
    "A astronomia observacional é uma área bastante ampla, abrangendo grandes áreas como o estudo do sistema solar, astrofísica estelar, estrutura de galáxias, astrofísica extragaláctica, cosmologia, entre outros. A cosmologia é a área responsável por estudar a origem, evolução, composição e estrutura do universo. Dentro da cosmologia existe o estudo que visa entender a evolução das galáxias e as suas distâncias em relação a Terra, esse estudo utiliza das técnicas de fotometria e espectroscopia de galáxias\n",
    "\n",
    "A espectroscopia é uma técnica que utiliza da emissão e absorção de objetos para extrair gráficos com fluxo energético por comprimento de onda, esses resultado é chamado de Spectral Energy Distribution (SED). E a fotometria utiliza de fotos para calcular o quão brilhante um objeto parece no céu, para isso os telescópios batem inúmeras fotos em diferentes comprimentos de onda para gerar catálogos de dados que depois são disponibilizados para estudos. \n",
    "Tudo no universo está em movimento, e de maneira geral, em relação a terra, os objetos podem estar se aproximando (blueshift), aparentemente parado (unshift) ou se afastando (redshift). Esse fenômeno foi primeiramente observado por volta de 1929 por Edwin Hubble utilizando a espectroscopia de galáxias, foi observado que a maioria dessas galáxias possuiam um desvio para o vermelho (redshift), esse estudo originou, mais tarde, a lei de Hubble. Atualmente, o universo pode ser estudado de maneira singular, onde se escolhem objetos para os telescópios observarem e extraírem dados mais específicos, ou em conjunto, onde se varre o céu para extrair a maior quantidade de informações de maneira mais geral sobre um grupo de objetos. \n",
    "Dentro do estudo de redshift de galáxias a área de tecnologia da informação está extremamente envolvida em todas as etapas do processo, desde a captura dos dados, na construção das imagens que vemos do universo e nas análises científicas, entre outros. No cálculo de redshift de galáxias em quantidade massiva, existem duas técnicas principais para processar esses dados: template fitting e machine learning. Para machine learning temos algoritmos que envolvem treinar uma inteligência artificial (IA) para aprender a calcular redshifts fotométricos, esse processo envolve a necessidade de uma amostra com resultados espectroscópicos já conhecidos para alimentar a IA. E, para o template fitting é utilizado algoritmos que fazem comparação com dados espectrográficos (templates) existentes de galáxias para determinar resultados dos dados fotométricos de entrada\n",
    "\n",
    "Com isso tudo o principal objetivo é compreender os principais conceitos dentro da astronomia voltada para o estudo de redshifts fotométricos reproduzindo os resultados de um dos algoritmos analisados no artigo: Photometric redshift analysis in the Dark Energy Survey Science Verification data escrito por Sanchez et al em 2014\n",
    "\n",
    "O Artigo aborda de uma maneira comparativa performática, como diferentes algoritmos desempenham utilizando dados coletados pela DECam, câmera utilizada pelo levantamento de energia escura, Dark Energy Survey (DES), no período de observação. O período de observação é uma fase de testes, onde acontecem testes de capturas de imagens do céu para análises e correções no telescópio. No total foram testados treze algoritmos, dentre eles cinco utilizando template based e nove machine learning. Também foram analisados dois conjuntos de dados, um principal (main) e outro de campo profundo (deep) que são dados de galáxias com menor magnitude aparente, menor brilho\n",
    "\n",
    "Para cada algoritmo foram realizadas quatro etapas de teste, escolhendo entre as amostras deep e a main para treino e validação comparando como os algoritmos se comportam em diferentes cenários. Esse estudo é relevante pois cada algoritmo possui um desempenho diferente de acordo com a natureza dos dados coletados, e saber qual algoritmo performa melhor em cada caso proporciona uma extração mais limpa (limpa?) de resultados. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187ee51",
   "metadata": {},
   "source": [
    "## 2 - Dados\n",
    "Descrição dos dados, resumo do QA (reproduzir Figs. 2, 3 e 4 do paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc307775",
   "metadata": {},
   "source": [
    "## 3 - Metodologia\n",
    "\n",
    "Descrever BPZ e métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df39b578",
   "metadata": {},
   "source": [
    "## 4 - Resultados\n",
    "\n",
    "Mostrar plots e métricas, comparação com os resultados do artigo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47074a55",
   "metadata": {},
   "source": [
    "## 5 - Conclusões\n",
    "\n",
    "Lições aprendidas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
