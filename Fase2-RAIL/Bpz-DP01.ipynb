{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BPZ RAIL - DP0.1\n",
    "\n",
    "no bringing to memory yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### common libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RAIL\n",
    "\n",
    "RAIL is an LSST-DESC software created to process different algorithms used to calculate photometric redshift. Its main goal is to minimize impact that different infrastructures can cause on different algorithms, for that it unifyes in a modular code supporting different inputs that different algorithms needs and padronizing the output so that it can be a more fair comparison between their results.\n",
    "\n",
    "Rail uses 4 principal libraries in its core: <br>\n",
    "_tables_io_: for data manipulation as hdf5 files, fits, etc. <br>\n",
    "_qp_: used to parametrize data PDFs for metrics calculation. <br>\n",
    "_ceci_: construct pipelines, produces a .yaml within the steps and configurations as threads. <br>\n",
    "_pzflow_: creates a flow for data creation. <br>\n",
    "\n",
    "#### Core.\n",
    "Where the main functions are going to manage the data and files that the program creates. It works based in the behavioral [chain of resposability](https://refactoring.guru/pt-br/design-patterns/chain-of-responsibility) pattern , where you create a flux in the code, where there is a request related/processed by a class handler that decides to pass it foward or not according to what is defined. So for that, what bpz does is create a class request (eg: Inform_BPZ_lite) that has all the inputs/configurations and is handled by its class handler (BPZ_lite).\n",
    "\n",
    "#### Creation.\n",
    "Contains all the support for data creation, as degradors, data flow creation, Column remapping, etc. It creates .hdf5 files with the data that is being manipulated.\n",
    "\n",
    "#### Estimation.\n",
    "This is where the photo-z codes are defined and executed.  <br>\n",
    "_inform_: this is where the PRIORS for template fitting are informed and the machine learning codes are trained. <br>\n",
    "_estimate_: where the algorith is executed though the .evaluate() function.\n",
    "The code is wrapped as a RAIL stage so that it can be run in a controlled way. Estimation code can be stored in a yaml file to be run as a ceci module.\n",
    "\n",
    "\n",
    "#### Evaluation.\n",
    "This step contais the metrics for performance of the estimated codes.\n",
    "<br>\n",
    "------\n",
    "For installation instructions check the official documentation: https://lsstdescrail.readthedocs.io/en/latest/source/installation.html <br>\n",
    "For Rail versions check: https://github.com/LSSTDESC/RAIL/releases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running RAIL, make sure it is up to date: \n",
    "```pip install rail --upgrade ``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rail\n",
    "import qp\n",
    "import tables_io\n",
    "\n",
    "from rail.core.data import TableHandle, DataStore\n",
    "from rail.core.stage import RailStage\n",
    "from rail.core.utilStages import ColumnMapper, TableConverter\n",
    "\n",
    "##from rail.creation.engines.flowEngine import FlowEngine, FlowPosterior\n",
    "\n",
    "from rail.estimation.algos.bpz_lite import Inform_BPZ_lite, BPZ_lite\n",
    "\n",
    "from rail.evaluation.evaluator import Evaluator\n",
    "\n",
    "#for rail versions\n",
    "help(rail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## General Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting some default number of rows for pandas. So that it doesnt display all of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining some variables that will help us with directories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURR_DIR = os.getcwd()\n",
    "RAIL_DIR = os.path.join(os.path.dirname(rail.__file__), '..')\n",
    "CURR_DIR, RAIL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading DP0.1 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_headers = [\n",
    "\"coadd_objects_id\",\n",
    "\"ra\",\n",
    "\"dec\",\n",
    "\"mag_g\",\n",
    "\"magerr_g\",\n",
    "\"mag_i\",\n",
    "\"magerr_i\",\n",
    "\"mag_r\",\n",
    "\"magerr_r\",\n",
    "\"mag_u\",\n",
    "\"magerr_u\",\n",
    "\"mag_y\",\n",
    "\"magerr_y\",\n",
    "\"mag_z\",\n",
    "\"magerr_z\",\n",
    "\"z_true\"\n",
    "]\n",
    "\n",
    "trainFile = os.path.join(CURR_DIR, 'dp0_train_random.csv')\n",
    "full_data = pd.read_csv(trainFile, usecols=interesting_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(full_data)//2\n",
    "\n",
    "train = full_data.sample(n=size,random_state=1, ignore_index=True)\n",
    "test = full_data.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  RAIL BPZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Core - Data Storage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically Rail store data in a transient class DataStore. This class associate keys and products in a dictionary, so that when program needs to excecute some step it has the functions that read, writes, and a data handlers.\n",
    "\n",
    "A DataHandler basically is a class that act like a handler for some data. What it does is that it associates the data with a file and the tool to read the file. The DataStore stores those handlers and their files associated with a key. So that when the algorithms process they are can propperly read the file content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_remmap = {\n",
    "\"coadd_objects_id\": \"id\",\n",
    "\"ra\": \"coord_ra\",\n",
    "\"dec\": \"coord_dec\",\n",
    "\"mag_g\": \"mag_g_lsst\",\n",
    "\"magerr_g\": \"mag_err_g_lsst\",\n",
    "\"mag_i\": \"mag_r_lsst\",\n",
    "\"magerr_i\": \"mag_err_r_lsst\",\n",
    "\"mag_r\": \"mag_i_lsst\",\n",
    "\"magerr_r\": \"mag_err_i_lsst\",\n",
    "\"mag_u\": \"mag_u_lsst\",\n",
    "\"magerr_u\": \"mag_err_u_lsst\",\n",
    "\"mag_y\": \"mag_y_lsst\",\n",
    "\"magerr_y\": \"mag_err_y_lsst\",\n",
    "\"mag_z\": \"mag_z_lsst\",\n",
    "\"magerr_z\": \"mag_err_z_lsst\",\n",
    "\"z_true\": \"redshift\"\n",
    "}\n",
    "\n",
    "\n",
    "col_remapper_train = ColumnMapper.make_stage(name='col_remapper_train', columns=columns_remmap)\n",
    "table_conv_train = TableConverter.make_stage(name='table_conv_train', output_format='numpyDict')\n",
    "\n",
    "results_remmaped = col_remapper_train(train)\n",
    "train_data = table_conv_train(results_remmaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, ceci stages basically configures the name and some configuration, so that when the stage runs, it return a TableHander, such as a PqHandler, Hdf5Handle or FitsHandle. \n",
    "\n",
    "obs: For machine leaning algorithms if may be necessary to configure a flowHandler too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(results_remmaped.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sample = tables_io.convertObj(train_data.data, tables_io.types.PD_DATAFRAME)\n",
    "type(full_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we should have somewhere a redshift result from other surveys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PRIORS - Inform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_file = os.path.join(CURR_DIR, 'configs/bpz.columns')\n",
    "inform_bpz = Inform_BPZ_lite.make_stage(\n",
    "    name='inform_bpzlite', \n",
    "    input=\"output_table_conv_train\", #\"inprogress_output_table_conv_train.hdf5\", \n",
    "    model='trained_BPZ_output.pkl', ##não precisaria isso pro bpz\n",
    "    hdf5_groupname='', \n",
    "    columns_file=columns_file\n",
    ")\n",
    "inform_bpz.config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "returned = inform_bpz.inform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Posterior -> Estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_remmaped = col_remapper_train(test)\n",
    "test_data = table_conv_train(results_remmaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_bpz = BPZ_lite.make_stage(\n",
    "    name='estimate_bpz', \n",
    "    hdf5_groupname='', \n",
    "    columns_file=columns_file, \n",
    "    model=inform_bpz.get_handle('model'))\n",
    "estimate_bpz.is_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_bpz.config_options['data_path'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpz_estimated = estimate_bpz.estimate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpz_estimated().build_tables()\n",
    "\n",
    "results_tables = tables_io.convertObj(bpz_estimated().build_tables()['ancil'], tables_io.types.PD_DATAFRAME)\n",
    "results_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_orig = test_data.data\n",
    "\n",
    "evaluator = Evaluator.make_stage(name=f'bpz_eval', truth=test_data_orig)\n",
    "result_dict = evaluator.evaluate(bpz_estimated, test_data_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tables = tables_io.convertObj(result_dict.data, tables_io.types.PD_DATAFRAME)\n",
    "results_tables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "___\n",
    "## VOU MEXER AINDA - Resultado pz x spec-z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmode = bpz_estimated().ancil['zmode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(test_data()['redshift'],zmode,s=1,c='k',label='simple bpz mode')\n",
    "plt.plot([0,3],[0,3],'r--');\n",
    "plt.xlabel(\"true redshift\")\n",
    "plt.ylabel(\"bpz photo-z\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
