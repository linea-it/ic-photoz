{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BPZ RAIL - DP0.2\n",
    "\n",
    "no bringing to memory yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### common libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### RAIL\n",
    "\n",
    "RAIL is a LSST-DESC software created to process different algorithms used to calculate photometric redshift. Its main goal is to minimize impact that different infrastructures can cause on different algorithms, for that it unifyes in a modular code supporting different inputs that different algorithms needs and padronizing the output so that it can be a more fair comparison between their results.\n",
    "\n",
    "Rail uses 4 principal libraries in its core: <br>\n",
    "_tables_io_: for data manipulation as hdf5 files, fits, etc. <br>\n",
    "_qp_: used to paremitrize data PDFs for metrics calculation. <br>\n",
    "_ceci_: construct pipelines, produces a .yaml within the steps and configurations as threads. <br>\n",
    "_pzflow_: creates a flow for data creation. <br>\n",
    "\n",
    "#### Core.\n",
    "Where the main functions are going to manage the data and files that the program creates. It works based in the behavioral chain of resposability pattern (https://refactoring.guru/pt-br/design-patterns/chain-of-responsibility), where you create a flux in the code, where there is a request related/processed by a class handler that decides to pass it foward or not according to what is defined. So for that, what bpz does is create a class request (eg: Inform_BPZ_lite) that has all the inputs/configurations and is handled by its class handler (BPZ_lite).\n",
    "\n",
    "#### Creation.\n",
    "Contain all the support for data creation, as degradors, data flow creation, Column remapping, etc. It creates .hdf5 files with the data that is being manipulated.\n",
    "\n",
    "#### Estimation.\n",
    "This is where the codes are defined and executed.  <br>\n",
    "inform: this is where the PRIORS for template fitting are informed and the machine learning codes are trained. <br>\n",
    "estimate: where the algorith is executed though the .evaluate() function.\n",
    "The code is wrapped as a RAIL stage so that it can be run in a controlled way. Estimation code can be stored in a yaml file to be run as a ceci module.\n",
    "\n",
    "\n",
    "#### Evaluation.\n",
    "This step contais the metrics for performance of the estimated codes.\n",
    "<br>\n",
    "------\n",
    "For installation instructions check the official documentation: https://lsstdescrail.readthedocs.io/en/latest/source/installation.html <br>\n",
    "For Rail versions check: https://github.com/LSSTDESC/RAIL/releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rail\n",
    "import qp\n",
    "import tables_io\n",
    "\n",
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "from rail.core.utilStages import ColumnMapper, TableConverter\n",
    "\n",
    "##from rail.creation.engines.flowEngine import FlowEngine, FlowPosterior\n",
    "\n",
    "from rail.estimation.algos.bpz_lite import Inform_BPZ_lite, BPZ_lite\n",
    "\n",
    "from rail.evaluation.evaluator import Evaluator\n",
    "\n",
    "#for rail versions\n",
    "help(rail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LSST - TAP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For accessing the data avaliable vis rubin science plataform we are going to use TAP.\n",
    "\n",
    "TAP is a protocol created to access general table data. \n",
    "It uses html and xml to configure and acess the data, wich can be tabular, with key values that are stored in tabbles, one column per keyword, and non tabular such as images, an n-dimensional data. \n",
    "Also, it passes as parameters atributes that are configurable, for example, the language and the query that we want trough:\n",
    "\n",
    "LANG=ADQL<br>\n",
    "QUERY=< ADQL query string >\n",
    "\n",
    "```xml\n",
    "    <capability standardID=\"ivo://ivoa.net/std/TAP\"> \n",
    "        <!-- BasicAA authentication bundle -->\n",
    "        <interface xsi:type=\"urx:Async\" role=\"std\" version=\"1.1\">\n",
    "          <accessURL use=\"base\">https://example.net/myTAP/auth-async</accessURL>\n",
    "          <securityMethod standardID=\"ivo://ivoa.net/sso#BasicAA\"/>\n",
    "        </interface>\n",
    "        <interface xsi:type=\"urx:Sync\" role=\"std\" version=\"1.1\">\n",
    "          <accessURL use=\"base\">https://example.net/myTAP/auth-sync</accessURL>\n",
    "          <securityMethod standardID=\"ivo://ivoa.net/sso#BasicAA\"/>\n",
    "        </interface>\n",
    "     </capability>\n",
    "```\n",
    "By default it returns a TapResult, witch is a wrapper for the Astropy Table that constains some metadata of the schema that is being stored, that can be accessed by some methods as getColumn(), getRecords(), etc.\n",
    "\n",
    "Its important to remember that TAP is a protocol to access the database where data is being stored, not the database itself.\n",
    "\n",
    "TAPResults documentation: https://pyvo.readthedocs.io/en/latest/api/pyvo.dal.TAPResults.html <br>\n",
    "Oficial documentation: https://www.ivoa.net/documents/TAP/ <br>\n",
    "video 1: https://www.youtube.com/watch?v=hFmhypXg7JA&list=PL7kL5D8ITGyXDJYyms0rjzt9o-wDg-rKQ <br>\n",
    "video 2:https://www.youtube.com/watch?v=BX10AI0WgMA&list=PL7kL5D8ITGyXDJYyms0rjzt9o-wDg-rKQ&index=2 <br>\n",
    "video 4:https://www.youtube.com/watch?v=szDdL7sqD68&list=PL7kL5D8ITGyXDJYyms0rjzt9o-wDg-rKQ&index=3 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.rsp import get_tap_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = get_tap_service()\n",
    "\n",
    "assert service is not None\n",
    "assert service.baseurl == \"https://data.lsst.cloud/api/tap\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Example of a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM tap_schema.schemas\"\n",
    "results = service.search(query)\n",
    "print(type(results))\n",
    "results.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## General Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting some default number of rows for pandas. So that it doesnt display all of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining some variables that will help us with directories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURR_DIR = os.getcwd()\n",
    "RAIL_DIR = os.path.join(os.path.dirname(rail.__file__), '..')\n",
    "CURR_DIR, RAIL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Reading DP0.2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the catalog with columns for dp 0.2 data can https://dm.lsst.org/sdm_schemas/browser/dp02.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rec = 1000\n",
    "use_center_coords = \"62, -37\"\n",
    "use_radius = \"1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['g', 'i', 'r', 'u', 'y', 'z']\n",
    "\n",
    "mags = \"\"\n",
    "for band in bands:\n",
    "    mags+= f\"scisql_nanojanskyToAbMag({band}_cModelFlux) AS mag_{band}_cModel, {band}_cModelFluxErr, \"\n",
    "\n",
    "columns_query = f\"objectId, {mags}coord_ra, coord_dec \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for this quey there is *detect_isPrimary* wich means that the source has no children, so that is already the final object. (this explanation is not very clear, but ok) and *r_extendedness* that defines if the object is a star or a galaxy, being 1 for galaxies and 0 for point objects such as starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT \" + columns_query + \\\n",
    "        \"FROM dp02_dc2_catalogs.Object \" + \\\n",
    "        \"WHERE CONTAINS(POINT('ICRS', coord_ra, coord_dec), CIRCLE('ICRS', \" + use_center_coords + \", \" + use_radius + \")) = 1 \" + \\\n",
    "        \"AND detect_isPrimary = 1 \" + \\\n",
    "        \"AND r_extendedness = 1 \" + \\\n",
    "        \"AND scisql_nanojanskyToAbMag(r_cModelFlux) > 17.0 \" + \\\n",
    "        \"AND scisql_nanojanskyToAbMag(r_cModelFlux) < 23.0 \"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = service.search(query, maxrec=max_rec)\n",
    "print(type(results))\n",
    "results = results.to_table()\n",
    "print(type(results))\n",
    "results_pd = results.to_pandas()\n",
    "results_pd.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  RAIL BPZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Core - Data Storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically Rail store data in a transient class DataStore, this class associate keys and products in a dictionary, so that when program need some step it has the functions that read, writes, and a data handlers.\n",
    "\n",
    "A DataHandler basically is a class that act like a handler for some data. What it does is that it associates the data with a file and the tool to read the file. The DataStore stores those handlers and their files associated with a key. So that when the algorithms process they are can propperly read the file content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_remmap = {\n",
    "\"objectId\": \"id\",\n",
    "\"coord_ra\": \"coord_ra\",\n",
    "\"coord_dec\": \"coord_dec\",\n",
    "\"mag_g_cModel\": \"mag_g_lsst\",\n",
    "\"g_cModelFluxErr\": \"mag_err_g_lsst\",\n",
    "\"mag_i_cModel\": \"mag_r_lsst\",\n",
    "\"i_cModelFluxErr\": \"mag_err_r_lsst\",\n",
    "\"mag_r_cModel\": \"mag_i_lsst\",\n",
    "\"r_cModelFluxErr\": \"mag_err_i_lsst\",\n",
    "\"mag_u_cModel\": \"mag_u_lsst\",\n",
    "\"u_cModelFluxErr\": \"mag_err_u_lsst\",\n",
    "\"mag_y_cModel\": \"mag_y_lsst\",\n",
    "\"y_cModelFluxErr\": \"mag_err_y_lsst\",\n",
    "\"mag_z_cModel\": \"mag_z_lsst\",\n",
    "\"z_cModelFluxErr\": \"mag_err_z_lsst\",\n",
    "\"detect_isPrimary\": \"detect_isPrimary\"\n",
    "}\n",
    "\n",
    "col_remapper_train = ColumnMapper.make_stage(name='col_remapper_train', columns=columns_remmap)\n",
    "table_conv_train = TableConverter.make_stage(name='table_conv_train', output_format='numpyDict')\n",
    "\n",
    "results_remmaped = col_remapper_train(results_pd)\n",
    "## the redshift value is required and it is going to come from other surveys \n",
    "results_remmaped.data[\"redshift\"] = 1\n",
    "\n",
    "train_data = table_conv_train(results_remmaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, ceci stages basically configures the name and some configuration, so that when the stage runs, it return a TableHander, such as a PqHandler, Hdf5Handle or FitsHandle. \n",
    "\n",
    "obs: For machine leaning algorithms if may be necessary to configure a flowHandler too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(results_remmaped), type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_table = tables_io.convertObj(train_data.data, tables_io.types.PD_DATAFRAME)\n",
    "test_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we should have somewhere a redshift result from other surveys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PRIORS - Inform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observe what is happening with the aliases as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_file = os.path.join(CURR_DIR, 'configs/bpz.columns')\n",
    "inform_bpz = Inform_BPZ_lite.make_stage(\n",
    "    name='inform_bpzlite', \n",
    "    input=\"inprogress_output_table_conv_train.hdf5\", \n",
    "    model='trained_BPZ_output.pkl', ##não precisaria isso pro bpz\n",
    "    hdf5_groupname='', \n",
    "    columns_file=columns_file\n",
    ")\n",
    "inform_bpz.config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(inform_bpz.inform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "returned = inform_bpz.inform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inform_bpz.config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Posterior -> Estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_bpz = BPZ_lite.make_stage(\n",
    "    name='estimate_bpz', \n",
    "    hdf5_groupname='', \n",
    "    columns_file=columns_file, \n",
    "    model=inform_bpz.get_handle('model'))\n",
    "estimate_bpz.is_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(estimate_bpz.estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_bpz.config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpz_estimated = estimate_bpz.estimate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_bpz.config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bpz_estimated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(bpz_estimated())\n",
    "bpz_estimated().build_tables()\n",
    "\n",
    "results_tables = tables_io.convertObj(bpz_estimated().build_tables()['ancil'], tables_io.types.PD_DATAFRAME)\n",
    "results_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_orig = results_remmaped.data\n",
    "\n",
    "evaluator = Evaluator.make_stage(name=f'bpz_eval', truth=test_data_orig)\n",
    "result_dict = evaluator.evaluate(bpz_estimated, test_data_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(evaluator.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tables = tables_io.convertObj(result_dict.data, tables_io.types.PD_DATAFRAME)\n",
    "results_tables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "___\n",
    "## VOU MEXER AINDA - Resultado pz x spec-z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmode = bpz_estimated().ancil['zmode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(train_data()['redshift'],zmode,s=1,c='k',label='simple bpz mode')\n",
    "plt.plot([0,3],[0,3],'r--');\n",
    "plt.xlabel(\"true redshift\")\n",
    "plt.ylabel(\"bpz photo-z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PIPELINES CECI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ceci\n",
    "pipe = ceci.Pipeline.interactive()\n",
    "stages = [flow_engine_train, lsst_error_model_train, inv_redshift,\n",
    "          line_confusion, quantity_cut, col_remapper_train, table_conv_train,\n",
    "          flow_engine_test, lsst_error_model_test, col_remapper_test, table_conv_test,  \n",
    "          inform_knn, inform_fzboost, inform_bpz, estimate_knn, \n",
    "          estimate_fzboost, estimate_bpz, point_estimate_test,\n",
    "          naive_stack_test]\n",
    "for stage in stages:\n",
    "    pipe.add_stage(stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.initialize(dict(flow=flow_file), dict(output_dir='.', log_dir='.', resume=False), None)\n",
    "pipe.save('bpz_pipeline.yml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
